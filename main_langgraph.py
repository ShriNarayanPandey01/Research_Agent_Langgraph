"""
Main Entry Point for LangGraph Multi-Agent Research System
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from multi_agent_langgraph import run_research
from text_report_generator import save_text_report, generate_text_report

# Load environment variables from .env file
load_dotenv()


def main():
    """Main execution function"""
    
    # Get query from command line or use default
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = "What is the impact of AI on education?"
    
    # Get API key from environment
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("\n" + "="*80)
        print("âŒ ERROR: OPENAI_API_KEY not set!")
        print("="*80)
        print("\nğŸ”‘ Option 1: Create a .env file (Recommended)")
        print("   1. Copy .env.example to .env")
        print("   2. Edit .env and add your API key:")
        print("      OPENAI_API_KEY=sk-your-actual-key-here")
        print("\nğŸ”‘ Option 2: Set environment variable")
        print("   PowerShell: $env:OPENAI_API_KEY='your-key-here'")
        print("   CMD:        set OPENAI_API_KEY=your-key-here")
        print("   Linux/Mac:  export OPENAI_API_KEY='your-key-here'")
        print("\nğŸ“ Get your API key from: https://platform.openai.com/api-keys")
        print("="*80 + "\n")
        return 1
    
    # Configuration
    page_limit = 3  # 1-3: Concise, 4-7: Medium, 8-20: Full research paper
    include_visualizations = False  # Set to True to include charts/graphs
    
    print("\n" + "="*80)
    print("ğŸš€ STARTING LANGGRAPH MULTI-AGENT RESEARCH SYSTEM")
    print("="*80)
    
    try:
        # Run research
        results = run_research(
            query=query,
            api_key=api_key,
            page_limit=page_limit,
            include_visualizations=include_visualizations
        )
        
        # Save results to JSON
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"research_langgraph_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, default=str, ensure_ascii=False)
        
        # Generate and save text report
        text_report_file = f"research_report_{timestamp}.txt"
        save_text_report(results, text_report_file)
        
        print("="*80)
        print("âœ… RESEARCH COMPLETE")
        print("="*80)
        print(f"Tasks processed: {results['tasks_processed']}")
        print("="*80)
        print(f"\n\nğŸ’¾ Results saved to:")
        print(f"   ğŸ“Š JSON: {output_file}")
        print(f"   ğŸ“„ TEXT: {text_report_file}\n")
        
        # Print summary
        print("="*80)
        print("ï¿½ TASK SUMMARIES")
        print("="*80)
        
        analysis_results = results.get('analysis_results', [])
        for analysis in analysis_results:
            task_id = analysis.get('task_id', 'unknown')
            query = analysis.get('query', 'N/A')
            tools_used = analysis.get('tools_used', [])
            num_sources = len(analysis.get('web_data', {}).get('retrieved_data', {}).get('sources', []))
            
            print(f"\nTASK {task_id.upper()}: {query}")
            print(f"   ğŸ“š Sources: {num_sources} found")
            print(f"   ğŸ”¬ Analysis: {', '.join(tools_used) if tools_used else 'AI reasoning'}")
            print(f"   âœ… Validation complete")
        
        print("\n" + "="*80)
        
        # Extract executive summary
        synthesized = results.get('synthesized_result', {})
        if synthesized:
            print("\nğŸ“‹ EXECUTIVE SUMMARY:")
            print("â”€"*80)
            summary = synthesized.get('overall_summary', 'N/A')
            print(f"{summary}")
            print("â”€"*80)
            
            print("\nğŸ” Key Findings:")
            for i, finding in enumerate(synthesized.get('key_findings', [])[:5], 1):
                print(f"   {i}. {finding}")
            
            if synthesized.get('combined_insights'):
                print(f"\nğŸ’¡ Insights:")
                for i, insight in enumerate(synthesized.get('combined_insights', [])[:3], 1):
                    if isinstance(insight, dict):
                        print(f"   {i}. {insight.get('insight', insight)}")
                    else:
                        print(f"   {i}. {insight}")
            
            print(f"\nğŸ“ˆ Confidence Score: {synthesized.get('confidence_score', 'N/A')}")
        
        print(f"\nâ±ï¸  Completed at: {results['timestamp']}")
        print(f"ğŸ“„ Full results: {output_file}")
        print(f"ğŸ“‹ Text report: {text_report_file}")
        
        print("\n" + "="*80)
        print("âœ… RESEARCH COMPLETED SUCCESSFULLY")
        print("="*80 + "\n")
        
        # Display the text report in terminal
        print("\n" + "="*80)
        print("ğŸ“„ DISPLAYING FULL TEXT REPORT")
        print("="*80 + "\n")
        
        report_text = generate_text_report(results)
        print(report_text)
        
        print("\n" + "="*80)
        print("ğŸ’¾ Report saved to:", text_report_file)
        print("="*80 + "\n")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Research interrupted by user")
        return 1
        
    except Exception as e:
        print(f"\n\nâŒ Error during research: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
